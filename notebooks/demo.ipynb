{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Financial Chatbot - Interactive Demo\n",
    "\n",
    "This notebook demonstrates the RAG (Retrieval-Augmented Generation) chatbot system for answering financial questions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Setup**: Load environment and initialize components\n",
    "2. **Document Ingestion**: Process and embed financial documents\n",
    "3. **RAG Pipeline**: Query the system and retrieve answers\n",
    "4. **Analysis**: Visualize retrieval and performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(Path.cwd().parent / \".env\")\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize RAG Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import application modules\n",
    "from app.core.config import get_settings\n",
    "from app.core.embeddings import EmbeddingGenerator\n",
    "from app.services.pinecone_service import PineconeService\n",
    "from app.rag.retriever import PineconeRetriever\n",
    "from app.rag.chain import RAGChain\n",
    "\n",
    "# Load settings\n",
    "settings = get_settings()\n",
    "\n",
    "print(f\"✓ Settings loaded\")\n",
    "print(f\"  - Embedding Model: {settings.embedding_model}\")\n",
    "print(f\"  - LLM Model: {settings.llm_model}\")\n",
    "print(f\"  - Pinecone Index: {settings.pinecone_index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding generator\n",
    "print(\"Initializing embedding generator...\")\n",
    "embedding_gen = EmbeddingGenerator(settings.embedding_model)\n",
    "print(f\"✓ Embedding dimension: {embedding_gen.get_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone service\n",
    "print(\"Connecting to Pinecone...\")\n",
    "pinecone_service = PineconeService(\n",
    "    api_key=settings.pinecone_api_key,\n",
    "    environment=settings.pinecone_environment,\n",
    "    index_name=settings.pinecone_index_name\n",
    ")\n",
    "\n",
    "# Get index stats\n",
    "try:\n",
    "    stats = pinecone_service.get_index_stats()\n",
    "    print(f\"✓ Connected to Pinecone\")\n",
    "    print(f\"  - Total vectors: {stats.get('total_vector_count', 0)}\")\n",
    "    print(f\"  - Dimension: {stats.get('dimension', 0)}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Note: {str(e)}\")\n",
    "    print(\"  Run the ingestion script first if the index doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize retriever\n",
    "print(\"Initializing retriever...\")\n",
    "retriever = PineconeRetriever(\n",
    "    pinecone_service=pinecone_service,\n",
    "    embedding_generator=embedding_gen,\n",
    "    top_k=settings.top_k\n",
    ")\n",
    "print(\"✓ Retriever initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG chain\n",
    "print(\"Initializing RAG chain...\")\n",
    "rag_chain = RAGChain(\n",
    "    retriever=retriever,\n",
    "    openai_api_key=settings.openai_api_key,\n",
    "    model_name=settings.llm_model,\n",
    "    temperature=settings.temperature,\n",
    "    max_tokens=settings.max_tokens\n",
    ")\n",
    "print(\"✓ RAG chain initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display results\n",
    "def display_result(result):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"QUESTION: {result['question']}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nANSWER:\\n{result['answer']}\")\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"\\nSOURCES: {', '.join(result['sources'])}\")\n",
    "    print(f\"\\nRETRIEVED DOCUMENTS: {len(result['retrieved_docs'])}\")\n",
    "    print(f\"\\nTop 3 Most Relevant Chunks:\")\n",
    "    for i, doc in enumerate(result['retrieved_docs'][:3], 1):\n",
    "        print(f\"\\n  [{i}] Score: {doc['score']:.3f} | Source: {doc['source']}\")\n",
    "        print(f\"      {doc['text'][:150]}...\")\n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Query 1: Revenue Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What was TechCorp's total revenue in Q1 2024?\"\n",
    "result1 = rag_chain.invoke(question1, top_k=5)\n",
    "display_result(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Query 2: Financial Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"What is the Net Revenue Retention rate and what does it mean?\"\n",
    "result2 = rag_chain.invoke(question2, top_k=5)\n",
    "display_result(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Query 3: Strategic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = \"What are TechCorp's strategic priorities for 2024?\"\n",
    "result3 = rag_chain.invoke(question3, top_k=5)\n",
    "display_result(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Query 4: Complex Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question4 = \"Compare the gross margin between Q1 2024 and the full year 2023\"\n",
    "result4 = rag_chain.invoke(question4, top_k=5)\n",
    "display_result(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive query function\n",
    "def ask_question(question, top_k=5):\n",
    "    \"\"\"Ask a question and display formatted result\"\"\"\n",
    "    result = rag_chain.invoke(question, top_k=top_k)\n",
    "    display_result(result)\n",
    "    return result\n",
    "\n",
    "# Try your own questions here!\n",
    "# Example:\n",
    "# ask_question(\"What is the customer acquisition cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Query Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of test questions\n",
    "test_questions = [\n",
    "    \"What was the total revenue in Q1 2024?\",\n",
    "    \"What is the operating margin?\",\n",
    "    \"How much did TechCorp invest in R&D?\",\n",
    "    \"What are the main risk factors?\",\n",
    "    \"What is the customer count?\",\n",
    "]\n",
    "\n",
    "# Process all questions\n",
    "results = []\n",
    "for question in test_questions:\n",
    "    print(f\"Processing: {question}\")\n",
    "    result = rag_chain.invoke(question, top_k=3)\n",
    "    results.append({\n",
    "        'question': question,\n",
    "        'answer_length': len(result['answer']),\n",
    "        'num_sources': len(result['sources']),\n",
    "        'top_score': result['retrieved_docs'][0]['score'] if result['retrieved_docs'] else 0\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH QUERY RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrieval Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize retrieval scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Answer lengths\n",
    "axes[0].bar(range(len(df_results)), df_results['answer_length'])\n",
    "axes[0].set_xlabel('Query Index')\n",
    "axes[0].set_ylabel('Answer Length (characters)')\n",
    "axes[0].set_title('Response Length Distribution')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Top retrieval scores\n",
    "axes[1].bar(range(len(df_results)), df_results['top_score'], color='green')\n",
    "axes[1].set_xlabel('Query Index')\n",
    "axes[1].set_ylabel('Similarity Score')\n",
    "axes[1].set_title('Top Document Relevance Scores')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage answer length: {df_results['answer_length'].mean():.0f} characters\")\n",
    "print(f\"Average top score: {df_results['top_score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Document Retrieval Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which documents are most frequently retrieved\n",
    "source_counts = {}\n",
    "for question in test_questions:\n",
    "    result = rag_chain.invoke(question, top_k=3)\n",
    "    for source in result['sources']:\n",
    "        source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sources = list(source_counts.keys())\n",
    "counts = list(source_counts.values())\n",
    "\n",
    "plt.barh(sources, counts, color='steelblue')\n",
    "plt.xlabel('Times Retrieved')\n",
    "plt.title('Document Retrieval Frequency')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost frequently retrieved documents:\")\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  - {source}: {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conversational RAG (With History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a conversation\n",
    "chat_history = []\n",
    "\n",
    "# Turn 1\n",
    "q1 = \"What was TechCorp's revenue in Q1 2024?\"\n",
    "r1 = rag_chain.invoke(q1)\n",
    "print(f\"Q: {q1}\")\n",
    "print(f\"A: {r1['answer'][:200]}...\\n\")\n",
    "chat_history.append({\"question\": q1, \"answer\": r1['answer']})\n",
    "\n",
    "# Turn 2 (with context)\n",
    "q2 = \"How does that compare to the previous year?\"\n",
    "r2 = rag_chain.invoke_with_chat_history(q2, chat_history)\n",
    "print(f\"Q: {q2}\")\n",
    "print(f\"A: {r2['answer'][:200]}...\\n\")\n",
    "chat_history.append({\"question\": q2, \"answer\": r2['answer']})\n",
    "\n",
    "# Turn 3 (with more context)\n",
    "q3 = \"What were the main growth drivers?\"\n",
    "r3 = rag_chain.invoke_with_chat_history(q3, chat_history)\n",
    "print(f\"Q: {q3}\")\n",
    "print(f\"A: {r3['answer'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Embedding Similarity Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query variations\n",
    "queries = [\n",
    "    \"What was the revenue?\",\n",
    "    \"How much money did the company make?\",\n",
    "    \"Tell me about sales figures\",\n",
    "]\n",
    "\n",
    "print(\"Testing query variations...\\n\")\n",
    "for query in queries:\n",
    "    docs = retriever.retrieve(query, top_k=3)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"  Top score: {docs[0]['score']:.3f}\")\n",
    "    print(f\"  Source: {docs[0]['source']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RAG System Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Embedding Model: {settings.embedding_model}\")\n",
    "print(f\"✓ LLM Model: {settings.llm_model}\")\n",
    "print(f\"✓ Vector Database: Pinecone ({settings.pinecone_index_name})\")\n",
    "print(f\"✓ Documents Indexed: {stats.get('total_vector_count', 'N/A')}\")\n",
    "print(f\"✓ Embedding Dimension: {embedding_gen.get_dimension()}\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Add your own financial documents to data/sample_docs/\")\n",
    "print(\"  2. Run ingestion script to update the index\")\n",
    "print(\"  3. Query with domain-specific questions\")\n",
    "print(\"  4. Deploy the FastAPI server for production use\")\n",
    "print(\"  5. Integrate with your frontend application\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
